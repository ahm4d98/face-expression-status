{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:10.695834Z",
     "start_time": "2021-08-28T03:14:08.430199Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Conv2D,Dropout,Flatten,BatchNormalization,MaxPooling2D\n",
    "import os\n",
    "img_rows=48\n",
    "img_cols=48\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:10.710795Z",
     "start_time": "2021-08-28T03:14:10.698822Z"
    }
   },
   "outputs": [],
   "source": [
    "num_class=5\n",
    "batch_size=8\n",
    "train_data=r'C:\\Users\\ahmed hatem\\Downloads\\face-expression-recognition-dataset\\face-expression-recognition-dataset\\train'\n",
    "validate=r'C:\\Users\\ahmed hatem\\Downloads\\face-expression-recognition-dataset\\face-expression-recognition-dataset\\validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:10.771775Z",
     "start_time": "2021-08-28T03:14:10.711787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:10.787731Z",
     "start_time": "2021-08-28T03:14:10.772767Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\t\t\t\t\trescale=1./255,\n",
    "\t\t\t\t\trotation_range=30,\n",
    "\t\t\t\t\tshear_range=0.3,\n",
    "\t\t\t\t\tzoom_range=0.3,\n",
    "\t\t\t\t\twidth_shift_range=0.4,\n",
    "\t\t\t\t\theight_shift_range=0.4,\n",
    "\t\t\t\t\thorizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "\t\t\t\t\tfill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:10.802687Z",
     "start_time": "2021-08-28T03:14:10.788724Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:11.650928Z",
     "start_time": "2021-08-28T03:14:10.803684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "\t\t\t\t\ttrain_data,\n",
    "\t\t\t\t\tcolor_mode='grayscale',\n",
    "\t\t\t\t\ttarget_size=(48,48),\n",
    "\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\tshuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:14:11.885303Z",
     "start_time": "2021-08-28T03:14:11.651921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5937 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\t\t\t\t\t\t\tvalidate,\n",
    "\t\t\t\t\t\t\tcolor_mode='grayscale',\n",
    "\t\t\t\t\t\t\ttarget_size=(48,48),\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\t\t\tshuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.167708Z",
     "start_time": "2021-08-28T03:14:11.886295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,037\n",
      "Trainable params: 1,325,861\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed hatem\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3022/3022 [==============================] - 208s 68ms/step - loss: 1.9294 - accuracy: 0.2275 - val_loss: 1.5482 - val_accuracy: 0.3133\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54819, saving model to Emotion_little_vgg.h5\n",
      "Epoch 2/25\n",
      "3022/3022 [==============================] - 188s 62ms/step - loss: 1.5693 - accuracy: 0.2826 - val_loss: 1.5483 - val_accuracy: 0.3040\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.54819\n",
      "Epoch 3/25\n",
      "3022/3022 [==============================] - 186s 61ms/step - loss: 1.5615 - accuracy: 0.2903 - val_loss: 1.5364 - val_accuracy: 0.3180\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.54819 to 1.53640, saving model to Emotion_little_vgg.h5\n",
      "Epoch 4/25\n",
      "3022/3022 [==============================] - 188s 62ms/step - loss: 1.5575 - accuracy: 0.2932 - val_loss: 1.5450 - val_accuracy: 0.3180\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.53640\n",
      "Epoch 5/25\n",
      "3022/3022 [==============================] - 187s 62ms/step - loss: 1.5456 - accuracy: 0.2981 - val_loss: 1.4995 - val_accuracy: 0.3337\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.53640 to 1.49951, saving model to Emotion_little_vgg.h5\n",
      "Epoch 6/25\n",
      "3022/3022 [==============================] - 186s 62ms/step - loss: 1.5333 - accuracy: 0.3024 - val_loss: 1.4667 - val_accuracy: 0.34735334 - \n",
      "\n",
      "Epoch 00006: val_loss improved from 1.49951 to 1.46672, saving model to Emotion_little_vgg.h5\n",
      "Epoch 7/25\n",
      "3022/3022 [==============================] - 193s 64ms/step - loss: 1.5158 - accuracy: 0.3186 - val_loss: 1.4790 - val_accuracy: 0.3603\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.46672\n",
      "Epoch 8/25\n",
      "3022/3022 [==============================] - 194s 64ms/step - loss: 1.5060 - accuracy: 0.3214 - val_loss: 1.4439 - val_accuracy: 0.3633\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.46672 to 1.44388, saving model to Emotion_little_vgg.h5\n",
      "Epoch 9/25\n",
      "3022/3022 [==============================] - 194s 64ms/step - loss: 1.5029 - accuracy: 0.3213 - val_loss: 1.5575 - val_accuracy: 0.3410\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.44388\n",
      "Epoch 10/25\n",
      "3022/3022 [==============================] - 191s 63ms/step - loss: 1.4918 - accuracy: 0.3283 - val_loss: 1.3883 - val_accuracy: 0.3937\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.44388 to 1.38835, saving model to Emotion_little_vgg.h5\n",
      "Epoch 11/25\n",
      "3022/3022 [==============================] - 189s 63ms/step - loss: 1.4822 - accuracy: 0.3432 - val_loss: 1.3896 - val_accuracy: 0.4077\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.38835\n",
      "Epoch 12/25\n",
      "3022/3022 [==============================] - 193s 64ms/step - loss: 1.4804 - accuracy: 0.3463 - val_loss: 1.7601 - val_accuracy: 0.3020\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.38835\n",
      "Epoch 13/25\n",
      "3022/3022 [==============================] - 188s 62ms/step - loss: 1.4572 - accuracy: 0.3635 - val_loss: 1.4596 - val_accuracy: 0.4237\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.38835\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block-1\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-2 \n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-3\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-4 \n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-5\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-6\n",
    "\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-7\n",
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('Emotion_little_vgg.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples = 24176\n",
    "nb_validation_samples = 3006\n",
    "epochs=25\n",
    "\n",
    "history=model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:56:02.467472Z",
     "start_time": "2021-08-28T03:56:02.450517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f04cf2cfa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.279432Z",
     "start_time": "2021-08-28T03:55:37.168707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17610720844992344404\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.309589Z",
     "start_time": "2021-08-28T03:55:37.281133Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'tensorflow_backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3d00d838479b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'tensorflow_backend'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.310585Z",
     "start_time": "2021-08-28T03:14:07.638Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.312580Z",
     "start_time": "2021-08-28T03:14:07.639Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T03:55:37.313578Z",
     "start_time": "2021-08-28T03:14:07.639Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# adjust values to your needs\n",
    "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
